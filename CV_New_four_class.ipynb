{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "destroyed-clear",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\3dsva-pc-1\\.conda\\envs\\tensor2\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "c:\\users\\3dsva-pc-1\\.conda\\envs\\tensor2\\lib\\site-packages\\numpy\\.libs\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll\n",
      "c:\\users\\3dsva-pc-1\\.conda\\envs\\tensor2\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from PIL import Image\n",
    "import random\n",
    "#Dependencies\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "#CNN\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "import warnings\n",
    "import os\n",
    "import shutil\n",
    "from PIL import ImageFile\n",
    "warnings.simplefilter('error', Image.DecompressionBombWarning)\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "from PIL import Image\n",
    "Image.MAX_IMAGE_PIXELS = 1000000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "royal-picking",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.layers import Dense, Flatten, GlobalMaxPooling2D\n",
    "from keras.callbacks import CSVLogger\n",
    "from livelossplot.keras import PlotLossesCallback\n",
    "import efficientnet.keras as efn\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model \n",
    "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
    "from keras import backend as k \n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "lesser-oracle",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "proper-salon",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_LOGS_FILE = \"training_logs.csv\"\n",
    "MODEL_SUMMARY_FILE = \"model_summary.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "crucial-binding",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetFolderName='datasets4'\n",
    "MODEL_FILENAME=\"model_cv.h5\"\n",
    "sourceFiles=[]\n",
    "classLabels=['Background', 'Ferny', 'Strappy','Rounded']\n",
    "def transferBetweenFolders(source, dest, splitRate):   \n",
    "    global sourceFiles\n",
    "    sourceFiles=os.listdir(source)\n",
    "    if(len(sourceFiles)!=0):\n",
    "        transferFileNumbers=int(len(sourceFiles)*splitRate)\n",
    "        transferIndex=random.sample(range(0, len(sourceFiles)), transferFileNumbers)\n",
    "        for eachIndex in transferIndex:\n",
    "            shutil.move(source+str(sourceFiles[eachIndex]), dest+str(sourceFiles[eachIndex]))\n",
    "    else:\n",
    "        print(\"No file moved. Source empty!\")\n",
    "        \n",
    "def transferAllClassBetweenFolders(source, dest, splitRate):\n",
    "    for label in classLabels:\n",
    "        transferBetweenFolders(datasetFolderName+'/'+source+'/'+label+'/', \n",
    "                               datasetFolderName+'/'+dest+'/'+label+'/', \n",
    "                               splitRate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "competitive-arkansas",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, check if test folder is empty or not, if not transfer all existing files to train\n",
    "#transferAllClassBetweenFolders('test', 'train', 1.0)\n",
    "# Now, split some part of train data into the test folders.\n",
    "#transferAllClassBetweenFolders('train', 'test', 0.20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "entertaining-contact",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=[]\n",
    "Y=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "gross-guess",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareNameWithLabels(folderName):\n",
    "    sourceFiles=os.listdir(datasetFolderName+'/train/'+folderName)\n",
    "    for val in sourceFiles:\n",
    "        X.append(val)\n",
    "        if(folderName==classLabels[0]):\n",
    "            Y.append(0)\n",
    "        elif(folderName==classLabels[1]):\n",
    "            Y.append(1)\n",
    "        elif(folderName==classLabels[2]):\n",
    "            Y.append(2)\n",
    "        else:\n",
    "            Y.append(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "atmospheric-playing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Organize file names and class labels in X and Y variables\n",
    "prepareNameWithLabels(classLabels[0])\n",
    "prepareNameWithLabels(classLabels[1])\n",
    "prepareNameWithLabels(classLabels[2]) \n",
    "prepareNameWithLabels(classLabels[3]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "significant-response",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.asarray(X)\n",
    "Y=np.asarray(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "polyphonic-sucking",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 456\n",
    "IMAGE_WIDTH, IMAGE_HEIGHT = IMAGE_SIZE, IMAGE_SIZE\n",
    "#EPOCHS = 10\n",
    "BATCH_SIZE = 32\n",
    "TEST_SIZE = 30\n",
    "\n",
    "input_shape = (IMAGE_WIDTH, IMAGE_HEIGHT, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "military-channel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning rate\n",
    "\n",
    "#activationFunction='relu'\n",
    "def getModel():\n",
    "    \n",
    "    model = Sequential()\n",
    "    efficient_net = efn.EfficientNetB5(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    #efficient_net.trainable = False\n",
    "    for index, layer in enumerate(efficient_net.layers):\n",
    "        if index < 761:\n",
    "            layer.trainable = False\n",
    "\n",
    "  \n",
    "    model.add(efficient_net)\n",
    "    #model.add(GlobalMaxPooling2D())\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Flatten())\n",
    "    # if dropout_rate > 0:\n",
    "    #     model.add(layers.Dropout(dropout_rate, name=\"dropout_out\"))\n",
    "    # model.add(layers.Dense(256, activation='relu', name=\"fc1\"))\n",
    "    model.add(Dense(4, activation='softmax')) #, name=\"output\"\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "            optimizer=RMSprop(lr=0.0001),\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "    with open(MODEL_SUMMARY_FILE,\"w\") as fh:\n",
    "        model.summary(print_fn=lambda line: fh.write(line + \"\\n\"))\n",
    "       \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "seventh-series",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_metrics(y_true, y_pred):\n",
    "    accuracy=accuracy_score(y_true, y_pred)\n",
    "    precision=precision_score(y_true, y_pred,average='weighted')\n",
    "    f1Score=f1_score(y_true, y_pred, average='weighted') \n",
    "    print(\"Accuracy  : {}\".format(accuracy))\n",
    "    print(\"Precision : {}\".format(precision))\n",
    "    print(\"f1Score : {}\".format(f1Score))\n",
    "    cm=confusion_matrix(y_true, y_pred)\n",
    "    print(cm)\n",
    "    return accuracy, precision, f1Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "unexpected-limit",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input image dimensions\n",
    "img_rows, img_cols =  456, 456\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "advisory-family",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path=datasetFolderName+'/train/'\n",
    "validation_path=datasetFolderName+'/validation/'\n",
    "test_path=datasetFolderName+'/test/'\n",
    "model=getModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "generous-booth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    }
   ],
   "source": [
    "checkpoint = ModelCheckpoint(\"effee44.h5\", monitor='accuracy', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='accuracy', min_delta=0, patience=5, verbose=1, mode='auto')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aging-uncertainty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for fold 1\n",
      "Found 44638 images belonging to 4 classes.\n",
      "Found 8930 images belonging to 4 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\3dsva-pc-1\\.conda\\envs\\tensor2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1395/1395 [==============================] - 2222s 2s/step - loss: 0.5399 - accuracy: 0.8692\n",
      "\n",
      "Epoch 00001: accuracy improved from -inf to 0.92121, saving model to effee44.h5\n",
      "Epoch 2/5\n",
      "1395/1395 [==============================] - 1788s 1s/step - loss: 0.1425 - accuracy: 0.9541\n",
      "\n",
      "Epoch 00002: accuracy improved from 0.92121 to 0.95602, saving model to effee44.h5\n",
      "Epoch 3/5\n",
      "1395/1395 [==============================] - 1706s 1s/step - loss: 0.1246 - accuracy: 0.9619\n",
      "\n",
      "Epoch 00003: accuracy improved from 0.95602 to 0.96324, saving model to effee44.h5\n",
      "Epoch 4/5\n",
      "1395/1395 [==============================] - 1711s 1s/step - loss: 0.1188 - accuracy: 0.9665\n",
      "\n",
      "Epoch 00004: accuracy improved from 0.96324 to 0.96689, saving model to effee44.h5\n",
      "Epoch 5/5\n",
      "1395/1395 [==============================] - 1692s 1s/step - loss: 0.1138 - accuracy: 0.9690\n",
      "\n",
      "Epoch 00005: accuracy improved from 0.96689 to 0.96828, saving model to effee44.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\3dsva-pc-1\\.conda\\envs\\tensor2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Performance on Validation data***\n",
      "Accuracy  : 0.9764837625979843\n",
      "Precision : 0.9767588773834806\n",
      "f1Score : 0.9765085199725324\n",
      "[[1852    1   67    1]\n",
      " [   0 1660   45   18]\n",
      " [   9   23 2829   14]\n",
      " [   0   21   11 2379]]\n",
      "Results for fold 2\n",
      "Found 44638 images belonging to 4 classes.\n",
      "Found 8930 images belonging to 4 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\3dsva-pc-1\\.conda\\envs\\tensor2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1395/1395 [==============================] - 1700s 1s/step - loss: 0.1199 - accuracy: 0.9684\n",
      "\n",
      "Epoch 00001: accuracy improved from 0.96828 to 0.96841, saving model to effee44.h5\n",
      "Epoch 2/5\n",
      "1395/1395 [==============================] - 1717s 1s/step - loss: 0.1143 - accuracy: 0.9701\n",
      "\n",
      "Epoch 00002: accuracy improved from 0.96841 to 0.97007, saving model to effee44.h5\n",
      "Epoch 3/5\n",
      "1395/1395 [==============================] - 1702s 1s/step - loss: 0.1082 - accuracy: 0.9733\n",
      "\n",
      "Epoch 00003: accuracy improved from 0.97007 to 0.97327, saving model to effee44.h5\n",
      "Epoch 4/5\n",
      "1395/1395 [==============================] - 1713s 1s/step - loss: 0.1067 - accuracy: 0.9747\n",
      "\n",
      "Epoch 00004: accuracy improved from 0.97327 to 0.97469, saving model to effee44.h5\n",
      "Epoch 5/5\n",
      "1395/1395 [==============================] - 1707s 1s/step - loss: 0.1074 - accuracy: 0.9750\n",
      "\n",
      "Epoch 00005: accuracy improved from 0.97469 to 0.97495, saving model to effee44.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\3dsva-pc-1\\.conda\\envs\\tensor2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Performance on Validation data***\n",
      "Accuracy  : 0.9837625979843225\n",
      "Precision : 0.983931643901781\n",
      "f1Score : 0.9836714661426328\n",
      "[[1915    0    6    0]\n",
      " [   1 1626   47   49]\n",
      " [  26    2 2843    4]\n",
      " [   2    3    5 2401]]\n",
      "Results for fold 3\n",
      "Found 44638 images belonging to 4 classes.\n",
      "Found 8930 images belonging to 4 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\3dsva-pc-1\\.conda\\envs\\tensor2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1395/1395 [==============================] - 1715s 1s/step - loss: 0.1159 - accuracy: 0.9738\n",
      "\n",
      "Epoch 00001: accuracy did not improve from 0.97495\n",
      "Epoch 2/5\n",
      "1395/1395 [==============================] - 1703s 1s/step - loss: 0.1081 - accuracy: 0.9754\n",
      "\n",
      "Epoch 00002: accuracy improved from 0.97495 to 0.97536, saving model to effee44.h5\n",
      "Epoch 3/5\n",
      "1395/1395 [==============================] - 1697s 1s/step - loss: 0.1027 - accuracy: 0.9767\n",
      "\n",
      "Epoch 00003: accuracy improved from 0.97536 to 0.97675, saving model to effee44.h5\n",
      "Epoch 4/5\n",
      "1395/1395 [==============================] - 1704s 1s/step - loss: 0.1035 - accuracy: 0.9776\n",
      "\n",
      "Epoch 00004: accuracy improved from 0.97675 to 0.97762, saving model to effee44.h5\n",
      "Epoch 5/5\n",
      "1395/1395 [==============================] - 5779s 4s/step - loss: 0.1067 - accuracy: 0.9775\n",
      "\n",
      "Epoch 00005: accuracy did not improve from 0.97762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\3dsva-pc-1\\.conda\\envs\\tensor2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Performance on Validation data***\n",
      "Accuracy  : 0.9893617021276596\n",
      "Precision : 0.9894035336838998\n",
      "f1Score : 0.9893489546094716\n",
      "[[1920    0    1    0]\n",
      " [   2 1682    8   31]\n",
      " [  24   13 2833    6]\n",
      " [   0    8    2 2400]]\n",
      "Results for fold 4\n",
      "Found 44638 images belonging to 4 classes.\n",
      "Found 8930 images belonging to 4 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\3dsva-pc-1\\.conda\\envs\\tensor2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1395/1395 [==============================] - 1512s 1s/step - loss: 0.1075 - accuracy: 0.9769\n",
      "\n",
      "Epoch 00001: accuracy did not improve from 0.97762\n",
      "Epoch 2/5\n",
      " 859/1395 [=================>............] - ETA: 9:51 - loss: 0.0983 - accuracy: 0.9783"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "skf.get_n_splits(X, Y)\n",
    "foldNum=0\n",
    "for train_index, val_index in skf.split(X, Y):\n",
    "    #First cut all images from validation to train (if any exists)\n",
    "    transferAllClassBetweenFolders('validation', 'train', 1.0)\n",
    "    foldNum+=1\n",
    "    print(\"Results for fold\",foldNum)\n",
    "    X_train, X_val = X[train_index], X[val_index]\n",
    "    Y_train, Y_val = Y[train_index], Y[val_index]\n",
    "    # Move validation images of this fold from train folder to the validation folder\n",
    "    for eachIndex in range(len(X_val)):\n",
    "        classLabel=''\n",
    "        if(Y_val[eachIndex]==0):\n",
    "            classLabel=classLabels[0]\n",
    "        elif(Y_val[eachIndex]==1):\n",
    "            classLabel=classLabels[1]\n",
    "        elif(Y_val[eachIndex]==2):\n",
    "            classLabel=classLabels[2]\n",
    "        else:\n",
    "            classLabel=classLabels[3]   \n",
    "        #Then, copy the validation images to the validation folder\n",
    "        shutil.move(datasetFolderName+'/train/'+classLabel+'/'+X_val[eachIndex], \n",
    "                    datasetFolderName+'/validation/'+classLabel+'/'+X_val[eachIndex])\n",
    "        \n",
    "    train_datagen = ImageDataGenerator(\n",
    "                rescale=1./255,\n",
    "        \t\tzoom_range=0.20,\n",
    "            \tfill_mode=\"nearest\"\n",
    "                )\n",
    "    validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "        \n",
    "    #Start ImageClassification Model\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        train_path,\n",
    "        target_size=(img_rows, img_cols),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical',\n",
    "        subset='training')\n",
    "\n",
    "    validation_generator = validation_datagen.flow_from_directory(\n",
    "            validation_path,\n",
    "            target_size=(img_rows, img_cols),\n",
    "            batch_size=32,\n",
    "            class_mode=None,  # only data, no labels\n",
    "            shuffle=False)   \n",
    "   \n",
    "    # fit model\n",
    "    history=model.fit_generator(train_generator, \n",
    "                        epochs=5, callbacks = [checkpoint, early])\n",
    "    \n",
    "    predictions = model.predict_generator(validation_generator, verbose=0)\n",
    "    yPredictions = np.argmax(predictions, axis=1)\n",
    "    true_classes = validation_generator.classes\n",
    "    # evaluate validation performance\n",
    "    print(\"***Performance on Validation data***\")    \n",
    "    valAcc, valPrec, valFScore = my_metrics(true_classes, yPredictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excited-sharing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============TESTING=============\n",
    "print(\"==============TEST RESULTS============\")\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        test_path,\n",
    "        target_size=(img_rows, img_cols),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,\n",
    "        shuffle=False) \n",
    "predictions = model.predict(test_generator, verbose=1)\n",
    "yPredictions = np.argmax(predictions, axis=1)\n",
    "true_classes = test_generator.classes\n",
    "\n",
    "testAcc,testPrec, testFScore = my_metrics(true_classes, yPredictions)\n",
    "model.save(MODEL_FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conditional-public",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"newnew.pb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "figured-being",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "nominated-mistress",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "149"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seasonal-honor",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "common-miniature",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(149,)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "running-evaluation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "149"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "critical-priority",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(149,)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "later-behavior",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "afraid-kernel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44,)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "spoken-security",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "affected-bangkok",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44,)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "successful-salem",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "222"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "christian-northwest",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "222"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "owned-angola",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strappy\n"
     ]
    }
   ],
   "source": [
    "print(classLabels[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "undefined-distance",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "western-pilot",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
